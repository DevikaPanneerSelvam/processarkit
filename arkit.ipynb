{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block after 'else' statement on line 1421 (init_arkit.py, line 1424)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[0;36m(most recent call last)\u001b[0m:\n",
      "\u001b[0m  File \u001b[1;32m~/miniconda3/envs/master_project/lib/python3.10/site-packages/IPython/core/interactiveshell.py:3579\u001b[0m in \u001b[1;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\u001b[0m\n",
      "\u001b[0;36m  Cell \u001b[0;32mIn[1], line 6\u001b[0;36m\n\u001b[0;31m    import init_arkit\u001b[0;36m\n",
      "\u001b[0;36m  File \u001b[0;32m~/Desktop/CV_Project/ManiSkill/Master_Project/init_arkit.py:1424\u001b[0;36m\u001b[0m\n\u001b[0;31m    except Exception as e:\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block after 'else' statement on line 1421\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import os\n",
    "from pathlib import Path\n",
    "import subprocess\n",
    "import requests\n",
    "import init_arkit\n",
    "import cv2 \n",
    "import json \n",
    "print(\"INIT FILE:\", init_arkit.__file__)\n",
    "import importlib\n",
    "importlib.reload(init_arkit)\n",
    "\n",
    "def download_file(file_url: str, dest_path: str | os.PathLike) -> bool:\n",
    "    \"\"\"\n",
    "    Download a single file from `file_url` and save it to `dest_path`.\n",
    "\n",
    "    Returns:\n",
    "        True if the download succeeds, False otherwise.\n",
    "    \"\"\"\n",
    "    dest_path = Path(dest_path)\n",
    "    try:\n",
    "        print(f\"Downloading {file_url} â†’ {dest_path}\")\n",
    "        response = requests.get(file_url, timeout=60)\n",
    "        response.raise_for_status()\n",
    "        dest_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "        with dest_path.open('wb') as f:\n",
    "            f.write(response.content)\n",
    "        print(f\"âœ“ Downloaded: {dest_path}\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"âœ— Failed to download {file_url}: {e}\")\n",
    "        return False\n",
    "    \n",
    "# -------------------------------------------------------------\n",
    "# Download a single ARKit scene's labelmaker\n",
    "# -------------------------------------------------------------\n",
    "def download_arkit_labelmaker(video_id: str, split: str, scene_dir: Path) -> None:\n",
    "    \"\"\"\n",
    "    Downloads a single ARKit scene's label and mesh information.\n",
    "    Prints the scene name before and after download.\n",
    "    \"\"\"\n",
    "    print(\"\\n===============================================\")\n",
    "    print(f\"ðŸ“Œ Downloading ARKit labelmaker: {video_id}  (split: {split})\")\n",
    "    print(\"===============================================\")\n",
    "\n",
    "    # files we always need for processing\n",
    "    label_files = ['labels.txt', 'point_lifted_mesh.ply']\n",
    "\n",
    "    # base URLs for fetching labels and meshes\n",
    "    labels_base_url = \"https://huggingface.co/datasets/labelmaker/arkit_labelmaker/raw/main\"\n",
    "    ply_base_url = \"https://huggingface.co/datasets/labelmaker/arkit_labelmaker/resolve/main\"\n",
    "\n",
    "    # Download the two required annotation assets into the scene folder\n",
    "    for file_name in label_files:\n",
    "        file_url = (\n",
    "            f\"{ply_base_url}/{split}/{video_id}/{file_name}\"\n",
    "            if file_name.endswith(\".ply\")\n",
    "            else f\"{labels_base_url}/{split}/{video_id}/{file_name}\"\n",
    "        )\n",
    "        dest_path = scene_dir / file_name\n",
    "        download_file(file_url, dest_path)\n",
    "\n",
    "    print(f\"ðŸŽ‰ Finished downloading scene's labelmaker: {video_id}\")\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# Download a single ARKit scene (simplified)\n",
    "# -------------------------------------------------------------\n",
    "def download_arkit_scene(video_id: str, split: str, download_dir: str = \"arkitscenes\") -> None:\n",
    "    \"\"\"\n",
    "    Downloads a single ARKit scene using download_data.py.\n",
    "    Prints the scene name before and after download.\n",
    "    \"\"\"\n",
    "    print(\"\\n===============================================\")\n",
    "    print(f\"ðŸ“Œ Downloading ARKit Scene: {video_id}  (split: {split})\")\n",
    "    print(\"===============================================\")\n",
    "\n",
    "    cmd = [\n",
    "        \"python3\", \"download_data.py\", \"raw\",\n",
    "        \"--video_id\", video_id,\n",
    "        \"--split\", split,\n",
    "        \"--download_dir\", download_dir,\n",
    "        \"--raw_dataset_assets\", \"lowres_wide.traj\",\n",
    "        \"vga_wide\", \"vga_wide_intrinsics\", \n",
    "    ]\n",
    "\n",
    "    subprocess.run(cmd, check=False)  # set check=True if you want it to crash on error\n",
    "\n",
    "    print(f\"ðŸŽ‰ Finished downloading scene: {video_id}\")\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# Read the ARKit split CSV and download scenes sequentially\n",
    "# -------------------------------------------------------------\n",
    "def download_arkit_dataset(csv_path: str = \"raw_train_val_splits.csv\",\n",
    "                           download_dir: str = \"arkitscenes\",\n",
    "                           output_fol: str = \"segmentation_summary\") -> None:\n",
    "    \"\"\"\n",
    "    Reads the ARKitScenes train/val CSV and downloads ALL scenes sequentially.\n",
    "    Prints the scene name for each one.\n",
    "    \"\"\"\n",
    "    csv_path = Path(csv_path)\n",
    "    if not csv_path.exists():\n",
    "        print(f\"CSV not found: {csv_path}\")\n",
    "        return\n",
    "\n",
    "    print(f\"Reading split file: {csv_path}\")\n",
    "\n",
    "    with csv_path.open(\"r\") as f:\n",
    "        reader = csv.DictReader(f)\n",
    "\n",
    "        for row in reader:\n",
    "            print(\"Loaded row:\", row)  # TEMP DEBUG\n",
    "\n",
    "            video_id = row.get(\"video_id\") or row.get(\"id\") or row.get(\"scene_id\")\n",
    "            split = row.get(\"split\") or row.get(\"fold\") or row.get(\"scene_type\")\n",
    "\n",
    "            if not video_id or not split:\n",
    "                print(\"Skipping row because missing video_id or split:\", row)\n",
    "                continue\n",
    "            \n",
    "            output_dir = Path(output_fol) / video_id\n",
    "            output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "            download_arkit_scene(video_id, split, download_dir)\n",
    "\n",
    "            # Extract downloaded files from each scene or video id\n",
    "            scene_dir = Path(download_dir) / \"raw\" / split / video_id\n",
    "            intrinsics_dir = scene_dir / \"vga_wide_intrinsics\"   \n",
    "            traj_path = scene_dir / \"lowres_wide.traj\"\n",
    "            image_dir = scene_dir / \"vga_wide\"  \n",
    "\n",
    "            download_arkit_labelmaker(video_id, split, scene_dir)\n",
    "            \n",
    "            mesh_path = scene_dir / \"point_lifted_mesh.ply\"\n",
    "            labels_path = scene_dir / \"labels.txt\"\n",
    "\n",
    "            # Quick sanity check before continuing\n",
    "            if not (mesh_path.exists() and labels_path.exists() and traj_path.exists()):\n",
    "                print(f\"Missing required files for {video_id}, skipping.\")\n",
    "                return\n",
    "            \n",
    "            # --- Read camera poses from the trajectory file ---\n",
    "            try:\n",
    "                poses = init_arkit.read_traj(traj_path).items()\n",
    "            except Exception as e:\n",
    "                print(f\"Failed to read traj for {video_id}: {e}\")\n",
    "                return\n",
    "            \n",
    "            # --- Prepare stats container and where we'll later save it ---\n",
    "            stats_path = output_dir / f\"{video_id}.json\"\n",
    "            class_pixel_stats = {\n",
    "                \"door\": {},\n",
    "                \"switch\": {}\n",
    "            }\n",
    "\n",
    "            # --- Enumerate frames (every 10th PNG), and find nearest pose for each ---\n",
    "            png_files = sorted([f for f in os.listdir(image_dir) if f.endswith(\".png\")])\n",
    "            print(f\"Found {len(png_files)} PNG frames in {image_dir}\")\n",
    "\n",
    "            for idx, filename in enumerate(png_files):\n",
    "                if idx % 30 != 0:\n",
    "                    continue\n",
    "\n",
    "                extracted_ts = init_arkit.extract_timestamp_from_filename(filename)\n",
    "                if extracted_ts is None:\n",
    "                    print(f\"Invalid timestamp in filename: {filename}\")\n",
    "                    continue\n",
    "\n",
    "                closest_ts, (rotvec, transvec) = init_arkit.get_pose_for_nearest_timestamp(extracted_ts, poses)\n",
    "                print(f\"Image: {filename} â†’ Extracted TS: {extracted_ts} â†’ Closest Pose TS: {closest_ts}\")\n",
    "\n",
    "                # Build frame-specific file names/paths we need to process later\n",
    "                frame_name = f\"{video_id}_{extracted_ts}\"\n",
    "                pincam_path = intrinsics_dir / f\"{frame_name}.pincam\"\n",
    "                frame_path = image_dir / f\"{frame_name}.png\"\n",
    "\n",
    "                # Skip if either the intrinsics file or the image is missing\n",
    "                if not pincam_path.exists() or not frame_path.exists():\n",
    "                    print(f\"Missing data for frame {extracted_ts} in scene {video_id}, skipping frame.\")\n",
    "                    continue\n",
    "\n",
    "                # The heavy lifting (reading the image, projecting labels, collecting stats, and saving the overlay) comes next.\n",
    "                # We now have: rotvec, transvec, pincam_path, frame_path ready to use.\n",
    "                try:\n",
    "                    rgb_img = cv2.imread(str(frame_path))\n",
    "                    if rgb_img is None:\n",
    "                        print(f\"Failed to read image {frame_path}\")\n",
    "                        continue\n",
    "                \n",
    "                    # --------------------------------------------------\n",
    "                    # FIX ORIENTATION HERE (ONCE PER FRAME)\n",
    "                    # --------------------------------------------------\n",
    "                    raw_roll = init_arkit.pixel_roll(rotvec)\n",
    "                    snap_roll = init_arkit.snap_roll_to_canonical(raw_roll)\n",
    "\n",
    "                    if snap_roll is not None:\n",
    "                        A, nW, nH = init_arkit.compute_roll_affine(*rgb_img.shape[:2], snap_roll)\n",
    "                        rgb_img = cv2.warpAffine(\n",
    "                            rgb_img,\n",
    "                            A,\n",
    "                            (nW, nH),\n",
    "                            flags=cv2.INTER_LINEAR,\n",
    "                            borderMode=cv2.BORDER_CONSTANT,\n",
    "                            borderValue=(0, 0, 0)   # black background\n",
    "                        )\n",
    "\n",
    "                    projection, contains_target, label_counts, total_pixels, door_instances_2d = init_arkit.project_instance(\n",
    "                    mesh_path=mesh_path,\n",
    "                        labels_path=labels_path,\n",
    "                        pincam_path=str(pincam_path),\n",
    "                        rotation_vec=rotvec,\n",
    "                        translation_vec=transvec,\n",
    "                        rgb_frame=rgb_img,\n",
    "                        alpha=0.6,\n",
    "                    )\n",
    "\n",
    "                    # Update stats only for frames that contain the target category\n",
    "                    for obj_type, target_present in zip([\"door\"], contains_target):\n",
    "                        if not target_present:\n",
    "                            continue\n",
    "\n",
    "                        ts = extracted_ts\n",
    "\n",
    "                        if not door_instances_2d:\n",
    "                            continue\n",
    "\n",
    "                        for inst_id, inst_data in door_instances_2d.items():\n",
    "                            inst_id = str(inst_id)\n",
    "\n",
    "                            # Create instance bucket\n",
    "                            if inst_id not in class_pixel_stats[obj_type]:\n",
    "                                class_pixel_stats[obj_type][inst_id] = {}\n",
    "\n",
    "                            if ts not in class_pixel_stats[obj_type][inst_id]:\n",
    "                                class_pixel_stats[obj_type][inst_id][ts] = {\"labels\": []}\n",
    "\n",
    "                            # Record pixel counts + percentages for each label id in the projection\n",
    "                            for label_id, count in label_counts.items():\n",
    "                                percentage = (count / max(total_pixels, 1)) * 100.0\n",
    "                                class_pixel_stats[obj_type][inst_id][ts][\"labels\"].append({\n",
    "                                    \"label_id\": int(label_id),\n",
    "                                    \"pixel_count\": int(count),\n",
    "                                    \"pixel_percentage\": percentage\n",
    "                                })\n",
    "\n",
    "                    # Save visualization overlay\n",
    "                    overlay_path = Path(output_dir) / f\"overlay_{extracted_ts}.png\"\n",
    "                    cv2.imwrite(str(overlay_path), projection)\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"Error in scene {video_id}, frame {extracted_ts}: {e}\")\n",
    "                    continue\n",
    "\n",
    "            # --- After loop: persist the collected statistics for this scene ---\n",
    "            with (output_dir / f\"{video_id}.json\").open(\"w\") as jsonfile:\n",
    "                json.dump(class_pixel_stats, jsonfile, indent=4)\n",
    "            print(f\"Saved statistics for scene {video_id} to {stats_path}\")\n",
    "\n",
    "            init_arkit.run_molmo(\n",
    "                video_id=video_id,\n",
    "                json_path=output_dir / f\"{video_id}.json\",\n",
    "                image_path=image_dir,\n",
    "                output_dir=output_dir,\n",
    "                poses=poses\n",
    "            )\n",
    "# -------------------------------------------------------------\n",
    "# Main execution\n",
    "# -------------------------------------------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    import argparse\n",
    "\n",
    "    parser = argparse.ArgumentParser(description=\"Download ARKitScenes dataset one by one\")\n",
    "    parser.add_argument(\"--csv_path\", default=\"raw_train_val_splits.csv\")\n",
    "    parser.add_argument(\"--download_dir\", default=\"arkitscenes\")\n",
    "    parser.add_argument(\"--output_dir\", default=\"segmentation_summary\")\n",
    "\n",
    "    # FIX: allow Jupyter to pass extra arguments like --f=...\n",
    "    args, unknown = parser.parse_known_args()\n",
    "\n",
    "    download_arkit_dataset(\n",
    "        csv_path=args.csv_path,\n",
    "        download_dir=args.download_dir\n",
    "    )\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "master_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
